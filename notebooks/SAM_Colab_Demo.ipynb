{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# 1️⃣ Install Required Libraries\n",
    "# ─────────────────────────────────────────────\n",
    "!pip install requests matplotlib opencv-python numpy tqdm python-dotenv huggingface_hub nbconvert --quiet\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from google.colab import files\n",
    "from huggingface_hub import hf_hub_upload\n",
    "from IPython.display import FileLink, display, HTML\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 2️⃣ Add Notebook Metadata (Optional)\n",
    "# ─────────────────────────────────────────────\n",
    "__author__ = \"Your Name\"\n",
    "__version__ = \"1.0\"\n",
    "print(f\"Notebook Author: {__author__}, Version: {__version__}\")\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 3️⃣ Load Environment Variables (.env optional)\n",
    "# ─────────────────────────────────────────────\n",
    "load_dotenv()\n",
    "API_URL = os.getenv(\"API_URL\", \"http://localhost:8000/predict\")\n",
    "JWT_TOKEN = os.getenv(\"JWT_TOKEN\", \"demo-secret\")\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {JWT_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 4️⃣ Upload Images\n",
    "# ─────────────────────────────────────────────\n",
    "uploaded = files.upload()\n",
    "image_paths = list(uploaded.keys())\n",
    "print(f\"✅ Uploaded {len(image_paths)} image(s)\")\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 5️⃣ Run Inference and Visualize\n",
    "# ─────────────────────────────────────────────\n",
    "for IMG_PATH in tqdm(image_paths, desc=\"Running Inference\"):\n",
    "    try:\n",
    "        print(f\"\\n🔍 Processing: {IMG_PATH}\")\n",
    "        with open(IMG_PATH, \"rb\") as img_file:\n",
    "            image_bytes = img_file.read()\n",
    "        image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "\n",
    "        payload = {\n",
    "            \"image_base64\": image_base64,\n",
    "            \"normalize\": True\n",
    "        }\n",
    "\n",
    "        response = requests.post(API_URL, json=payload, headers=HEADERS)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            mask = np.array(result[\"mask\"]).reshape((256, 256))\n",
    "            inference_time = result.get(\"inference_time\", \"N/A\")\n",
    "            print(f\"⏱ Inference time: {inference_time} seconds\")\n",
    "\n",
    "            mask_binary = (mask > 0.5).astype(np.uint8)\n",
    "            image_np = np.array(Image.open(IMG_PATH).resize((256, 256)))\n",
    "            overlay = cv2.addWeighted(image_np, 0.6, cv2.cvtColor(mask_binary * 255, cv2.COLOR_GRAY2RGB), 0.4, 0)\n",
    "\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.title(\"Original Image\")\n",
    "            plt.imshow(image_np)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.title(\"Predicted Mask\")\n",
    "            plt.imshow(mask_binary, cmap='gray')\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(\"Overlay\")\n",
    "            plt.imshow(overlay)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            output_path = f\"outputs/pred_{os.path.splitext(IMG_PATH)[0]}.png\"\n",
    "            plt.savefig(output_path)\n",
    "            plt.show()\n",
    "            print(f\"📸 Saved: {output_path}\")\n",
    "        else:\n",
    "            print(f\"❌ API Error: {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception occurred: {str(e)}\")\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 6️⃣ Zip All Output Images\n",
    "# ─────────────────────────────────────────────\n",
    "zip_path = shutil.make_archive(\"sam_predictions\", 'zip', \"outputs\")\n",
    "print(\"📦 All predictions zipped as:\", zip_path)\n",
    "display(FileLink(zip_path))\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 7️⃣ (Optional) Upload to Hugging Face Hub\n",
    "# ─────────────────────────────────────────────\n",
    "# from huggingface_hub import login; login()\n",
    "# hf_hub_upload(\n",
    "#     folder_path=\"outputs\",\n",
    "#     repo_id=\"your-username/sam-results\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     commit_message=\"Upload SAM results\"\n",
    "# )\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 8️⃣ (Optional) Export to HTML and PDF\n",
    "# ─────────────────────────────────────────────\n",
    "!jupyter nbconvert --to html SAM_Colab_Demo.ipynb --output \"SAM_Report.html\"\n",
    "!jupyter nbconvert --to pdf SAM_Colab_Demo.ipynb --output \"SAM_Report.pdf\"\n",
    "\n",
    "print(\"📘 Exported HTML: SAM_Report.html\")\n",
    "print(\"📘 Exported PDF: SAM_Report.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
